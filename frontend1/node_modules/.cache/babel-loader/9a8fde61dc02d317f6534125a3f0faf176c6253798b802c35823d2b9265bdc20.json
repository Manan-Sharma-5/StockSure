{"ast":null,"code":"import { ContextualKeyword } from \"../parser/tokenizer/keywords\";\nimport { TokenType as tt } from \"../parser/tokenizer/types\";\n\n/**\n * Starting at a potential `assert` token remove the import assertion if there\n * is one.\n */\nexport function removeMaybeImportAssertion(tokens) {\n  if (tokens.matches2(tt.name, tt.braceL) && tokens.matchesContextual(ContextualKeyword._assert)) {\n    // assert\n    tokens.removeToken();\n    // {\n    tokens.removeToken();\n    tokens.removeBalancedCode();\n    // }\n    tokens.removeToken();\n  }\n}","map":{"version":3,"names":["ContextualKeyword","TokenType","tt","removeMaybeImportAssertion","tokens","matches2","name","braceL","matchesContextual","_assert","removeToken","removeBalancedCode"],"sources":["/Users/manan/Desktop/hach-unicorn/StockSure/frontend1/node_modules/sucrase/dist/esm/util/removeMaybeImportAssertion.js"],"sourcesContent":["import {ContextualKeyword} from \"../parser/tokenizer/keywords\";\nimport {TokenType as tt} from \"../parser/tokenizer/types\";\n\n\n/**\n * Starting at a potential `assert` token remove the import assertion if there\n * is one.\n */\nexport function removeMaybeImportAssertion(tokens) {\n  if (tokens.matches2(tt.name, tt.braceL) && tokens.matchesContextual(ContextualKeyword._assert)) {\n    // assert\n    tokens.removeToken();\n    // {\n    tokens.removeToken();\n    tokens.removeBalancedCode();\n    // }\n    tokens.removeToken();\n  }\n}\n"],"mappings":"AAAA,SAAQA,iBAAiB,QAAO,8BAA8B;AAC9D,SAAQC,SAAS,IAAIC,EAAE,QAAO,2BAA2B;;AAGzD;AACA;AACA;AACA;AACA,OAAO,SAASC,0BAA0BA,CAACC,MAAM,EAAE;EACjD,IAAIA,MAAM,CAACC,QAAQ,CAACH,EAAE,CAACI,IAAI,EAAEJ,EAAE,CAACK,MAAM,CAAC,IAAIH,MAAM,CAACI,iBAAiB,CAACR,iBAAiB,CAACS,OAAO,CAAC,EAAE;IAC9F;IACAL,MAAM,CAACM,WAAW,CAAC,CAAC;IACpB;IACAN,MAAM,CAACM,WAAW,CAAC,CAAC;IACpBN,MAAM,CAACO,kBAAkB,CAAC,CAAC;IAC3B;IACAP,MAAM,CAACM,WAAW,CAAC,CAAC;EACtB;AACF"},"metadata":{},"sourceType":"module","externalDependencies":[]}